{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNOE7Yqpl9+Q8JwpAhfhVCi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shayaani7/Machine-Learning-Projects/blob/main/Face_Attendance_OpenCV.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import face_recognition\n",
        "import os\n",
        "from datetime import datetime\n",
        "# from PIL import ImageGrab\n",
        "\n",
        "path = 'ImagesAttendance'\n",
        "images = []\n",
        "classNames = []\n",
        "myList = os.listdir(path)\n",
        "print(myList)\n",
        "for cl in myList:\n",
        "curImg = cv2.imread(f'{path}/{cl}')\n",
        "images.append(curImg)\n",
        "classNames.append(os.path.splitext(cl)[0])\n",
        "print(classNames)\n",
        "\n",
        "def findEncodings(images):\n",
        "encodeList = []\n",
        "for img in images:\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "encode = face_recognition.face_encodings(img)[0]\n",
        "encodeList.append(encode)\n",
        "return encodeList\n",
        "\n",
        "def markAttendance(name):\n",
        "with open('Attendance.csv','r+') as f:\n",
        "myDataList = f.readlines()\n",
        "nameList = []\n",
        "for line in myDataList:\n",
        "entry = line.split(',')\n",
        "nameList.append(entry[0])\n",
        "if name not in nameList:\n",
        "now = datetime.now()\n",
        "dtString = now.strftime('%H:%M:%S')\n",
        "f.writelines(f'n{name},{dtString}')\n",
        "\n",
        "#### FOR CAPTURING SCREEN RATHER THAN WEBCAM\n",
        "# def captureScreen(bbox=(300,300,690+300,530+300)):\n",
        "#     capScr = np.array(ImageGrab.grab(bbox))\n",
        "#     capScr = cv2.cvtColor(capScr, cv2.COLOR_RGB2BGR)\n",
        "#     return capScr\n",
        "\n",
        "encodeListKnown = findEncodings(images)\n",
        "print('Encoding Complete')\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "success, img = cap.read()\n",
        "#img = captureScreen()\n",
        "imgS = cv2.resize(img,(0,0),None,0.25,0.25)\n",
        "imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "facesCurFrame = face_recognition.face_locations(imgS)\n",
        "encodesCurFrame = face_recognition.face_encodings(imgS,facesCurFrame)\n",
        "\n",
        "for encodeFace,faceLoc in zip(encodesCurFrame,facesCurFrame):\n",
        "matches = face_recognition.compare_faces(encodeListKnown,encodeFace)\n",
        "faceDis = face_recognition.face_distance(encodeListKnown,encodeFace)\n",
        "#print(faceDis)\n",
        "matchIndex = np.argmin(faceDis)\n",
        "\n",
        "if matches[matchIndex]:\n",
        "name = classNames[matchIndex].upper()\n",
        "#print(name)\n",
        "y1,x2,y2,x1 = faceLoc\n",
        "y1, x2, y2, x1 = y1*4,x2*4,y2*4,x1*4\n",
        "cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
        "cv2.rectangle(img,(x1,y2-35),(x2,y2),(0,255,0),cv2.FILLED)\n",
        "cv2.putText(img,name,(x1+6,y2-6),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
        "markAttendance(name)\n",
        "\n",
        "cv2.imshow('Webcam',img)\n",
        "cv2.waitKey(1)"
      ],
      "metadata": {
        "id": "2OdRvtN8Is3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if matches[matchIndex]:\n",
        "    name = classNames[matchIndex].upper()\n",
        "    #print(name)\n",
        "    y1,x2,y2,x1 = faceLoc\n",
        "    y1, x2, y2, x1 = y1*4,x2*4,y2*4,x1*4\n",
        "    cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
        "    cv2.rectangle(img,(x1,y2-35),(x2,y2),(0,255,0),cv2.FILLED)\n",
        "    cv2.putText(img,name,(x1+6,y2-6),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
        "    markAttendance(name)\n",
        "To find the unknown faces we will replace\n",
        "\n",
        "with this\n",
        "\n",
        "if faceDis[matchIndex]< 0.50:\n",
        "    name = classNames[matchIndex].upper()\n",
        "    markAttendance(name)\n",
        "else: name = 'Unknown'\n",
        "#print(name)\n",
        "y1,x2,y2,x1 = faceLoc\n",
        "y1, x2, y2, x1 = y1*4,x2*4,y2*4,x1*4\n",
        "cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
        "cv2.rectangle(img,(x1,y2-35),(x2,y2),(0,255,0),cv2.FILLED)\n",
        "cv2.putText(img,name,(x1+6,y2-6),cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
        "#All this does is to check if the distance to our min face is less than 0.5 or not. If its not then this means the person is unknown so we change the name to unknown and donâ€™t mark the attendance."
      ],
      "metadata": {
        "id": "z7iLHinDIyQT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}